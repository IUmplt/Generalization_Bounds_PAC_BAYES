{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd.function import Function\n",
    "from torch.autograd import Variable\n",
    "from math import log , pi\n",
    "import numpy as np\n",
    "fr\n",
    "\n",
    "from torchvision import transforms\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "from PacBayes_Loss import PacBayesLoss\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SIZE = 784\n",
    "HIDDEN_SIZE = [300 , 8 , 1200]\n",
    "NUM_CLASSES = 2\n",
    "NUM_EPOCHS = 20\n",
    "# BATCH_SIZE = np.size(x_train)\n",
    "LEARNING_RATE = 0.01\n",
    "MOMENTUM = 0.9\n",
    "\n",
    "Models = {'T-600' :FeedForwardNeuralNet(INPUT_SIZE, HIDDEN_SIZE[1], NUM_CLASSES),\n",
    "          'T-1200':FeedForwardNeuralNet(INPUT_SIZE, HIDDEN_SIZE[2], NUM_CLASSES),\n",
    "          'T2-300':FeedForwardNeuralNet2(INPUT_SIZE, HIDDEN_SIZE[0], NUM_CLASSES),\n",
    "          'T2-600':FeedForwardNeuralNet2(INPUT_SIZE, HIDDEN_SIZE[1], NUM_CLASSES),\n",
    "          'T2-1200':FeedForwardNeuralNet2(INPUT_SIZE, HIDDEN_SIZE[2], NUM_CLASSES),\n",
    "          'T3-600' :FeedForwardNeuralNet3(INPUT_SIZE, HIDDEN_SIZE[1], NUM_CLASSES) }\n",
    "\n",
    "net = Models['T-600']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alterning_targets(targets,label1_elements,label2_elements):\n",
    "    '''\n",
    "    We Change the classification task :\n",
    "    We produce a binary classification problem by mapping :\n",
    "    numbers {0,1,2,3,4} to label 0 and {5,6,7,8,9} to label 1\n",
    "    '''\n",
    "    new_targets = targets.copy()\n",
    "    new_targets[np.isin(new_targets, label1_elements)] = 0\n",
    "    new_targets[np.isin(new_targets, label2_elements)] = 1\n",
    "    \n",
    "    return new_targets\n",
    "\n",
    "import tensorflow as tf\n",
    "# Importing Tensorflow Dataset MNIST :\n",
    "label1_elements = np.arange(0,5)\n",
    "label2_elements = np.arange(5,10)\n",
    "mnist = tf.keras.datasets.mnist.load_data()\n",
    "(x_train, y_train), (x_test, y_test) = mnist\n",
    "x_train , y_train = x_train[:55000] , alterning_targets(y_train,label1_elements,label2_elements)[:55000]\n",
    "x_test , y_test = x_test , alterning_targets(y_test,label1_elements,label2_elements)\n",
    "\n",
    "class CustomMNIST(Dataset):\n",
    "    def __init__(self, data ,targets, height, width, transform=None):\n",
    "        \"\"\"\n",
    "        Constructing a custom Dataset of MNIST on Pytorch\n",
    "        Args:\n",
    "            height (int): image height\n",
    "            width (int): image width\n",
    "            transform: pytorch transforms for transforms and tensor conversion\n",
    "        \"\"\"\n",
    "        self.data = data\n",
    "        self.labels = targets\n",
    "        self.height = height\n",
    "        self.width = width\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        single_image_label = self.labels[index]\n",
    "        # Read each 784 pixels and reshape the 1D array ([784]) to 2D array ([28,28])\n",
    "        img_as_np = self.data[index].reshape(self.height, self.height).astype('uint8')\n",
    "        # Convert image from numpy array to PIL image, mode 'L' is for grayscale\n",
    "        img_as_img = Image.fromarray(img_as_np)\n",
    "        img_as_img = img_as_img.convert('L')\n",
    "        # Transform image to tensor\n",
    "        if self.transform is not None:\n",
    "            img_as_tensor = self.transform(img_as_img)\n",
    "        # Return image and the label\n",
    "        return (img_as_tensor, single_image_label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    \n",
    "transformations = transforms.Compose([transforms.ToTensor()])\n",
    "custom_mnist_train = \\\n",
    "    CustomMNIST(x_train,y_train,\n",
    "                             28, 28,\n",
    "                             transformations)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=custom_mnist_train,\n",
    "                                                    batch_size=1,\n",
    "                                                    shuffle=True)\n",
    "\n",
    "# testing data and loader\n",
    "custom_mnist_test = \\\n",
    "    CustomMNIST(x_test,y_test,\n",
    "                             28, 28,\n",
    "                             transformations)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=custom_mnist_test,\n",
    "                                                    batch_size=1,\n",
    "                                                    shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "0%3.4552266597747803\n",
      "tensor([-9.6013e-07, -4.2650e-07,  5.8031e-06,  ..., -6.6159e-07,\n",
      "        -1.5565e-07,  3.7464e-06])\n",
      "0%3.4644200801849365\n",
      "tensor([-5.9759e-07,  4.0508e-06,  6.6138e-06,  ...,  6.8097e-07,\n",
      "         1.9729e-06,  7.9730e-07])\n"
     ]
    }
   ],
   "source": [
    "def main(test_cuda=False):\n",
    "    print('-'*80)\n",
    "    device = torch.device(\"cuda\" if test_cuda else \"cpu\")\n",
    "    net = Models['T-600']\n",
    "    conf_param=0.025 \n",
    "    Precision= 100 \n",
    "    bound=0.1 \n",
    "    data_size= 55000\n",
    "    \n",
    "    lambda_prior_ = torch.tensor(-3. ,device=device).requires_grad_()\n",
    "    \n",
    "    sigma_posterior_ = torch.abs(parameters_to_vector(net.parameters())).requires_grad_()\n",
    "\n",
    "    ct = PacBayesLoss(lambda_prior_, sigma_posterior_, net, conf_param, Precision, bound, \n",
    "                      data_size).to(device)\n",
    "    \n",
    "    optimizer = torch.optim.RMSprop(ct.parameters(), lr = 0.001)\n",
    "    criterion  = nn.CrossEntropyLoss()\n",
    "    \n",
    "    \n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "            if i > 1:\n",
    "                break\n",
    "            print(\"\\r{}%\".format(100 * i // ct.data_size), end=\"\")\n",
    "            images = images.reshape(-1, 28 * 28).to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            loss1 = ct(net.parameters())\n",
    "            \n",
    "#             print(loss1.item())\n",
    "#             loss1.backward(retain_graph=True)\n",
    "            \n",
    "#             print(ct.flat_params.grad)\n",
    "            \n",
    "            modified_parameters = ct.flat_params + torch.randn(ct.d_size) * torch.exp(2 * ct.sigma_posterior_).abs()\n",
    "            indi = 0\n",
    "            for name,ind,shape_ in network_params(net):\n",
    "                net.state_dict()[name].data.copy_(modified_parameters[indi:indi+ind].view(shape_)) \n",
    "                indi = ind\n",
    "                \n",
    "        \n",
    "            \n",
    "            outputs = net(images)\n",
    "            loss2 = criterion(outputs.float(), labels.long())\n",
    "                \n",
    "#             loss = loss1 + loss2\n",
    "            \n",
    "            loss2.backward()\n",
    "            print(ct.flat_params.grad)\n",
    "            \n",
    "            \n",
    "#             optimizer.step()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    torch.manual_seed(500)\n",
    "    main(test_cuda=False)\n",
    "    if torch.cuda.is_available():\n",
    "        main(test_cuda=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = False\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "batch_size = 1\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=True, download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                   ])),\n",
    "    batch_size= batch_size, shuffle=True, **kwargs)\n",
    "\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                   ])),\n",
    "    batch_size= batch_size , shuffle=True, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
